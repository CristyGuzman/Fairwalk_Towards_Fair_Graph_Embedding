{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_directory = \"../Dataset/facebook\"\n",
    "if dataset_directory[-1] != '/':\n",
    "    dataset_directory = dataset_directory + '/'\n",
    "all_files = os.listdir(dataset_directory)\n",
    "egofeat_files = [file for file in all_files if (file.split('.')[1] == 'egofeat')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 107, 1684, 1912, 3437, 348, 3980, 414, 686, 698]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ego_nodes = [int(file.split('.')[0]) for file in egofeat_files]\n",
    "ego_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = {}\n",
    "for ego_node in ego_nodes:\n",
    "    nodes[ego_node] = set()\n",
    "    circles = open(dataset_directory + str(ego_node) + '.circles', 'r')\n",
    "    for line in circles:\n",
    "        line = line.split()\n",
    "        for n in line[1:]:\n",
    "            nodes[ego_node].add(int(n))\n",
    "    circles.close()\n",
    "    edges = open(dataset_directory + str(ego_node) + '.edges', 'r')\n",
    "    for line in edges:\n",
    "        line = line.split()\n",
    "        for n in line:\n",
    "            nodes[ego_node].add(int(n))\n",
    "    edges.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_list = {}\n",
    "for ego_node in ego_nodes:\n",
    "    edge_list = set()\n",
    "    \n",
    "    circles = open(dataset_directory + str(ego_node) + '.circles', 'r')\n",
    "    for line in circles:\n",
    "        line = line.split()\n",
    "        for n in line[1:]:\n",
    "            edge_list.add((min(ego_node, int(n)), max(ego_node, int(n))))\n",
    "    circles.close()\n",
    "    \n",
    "    edges = open(dataset_directory + str(ego_node) + '.edges', 'r')\n",
    "    for line in edges:\n",
    "        line = line.split()\n",
    "        one = int(line[0])\n",
    "        two = int(line[1])\n",
    "        edge_list.add((min(one, two), max(one, two)))        \n",
    "    edges.close()\n",
    "    edges_list[ego_node] = edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('../Edges/')\n",
    "except:\n",
    "    pass\n",
    "for ego_node in ego_nodes:\n",
    "    edges = list(edges_list[ego_node])\n",
    "    random.shuffle(edges)\n",
    "    size = len(edges)\n",
    "    for i in range(5):\n",
    "        edges_20 = edges[i * (size // 5):(i + 1) * (size // 5)]\n",
    "        edges_80 = edges[:i * (size // 5)] + edges[(i + 1) * (size // 5):]\n",
    "        \n",
    "        file = open('../Edges/edges_20_{}_{}.txt'.format(ego_node, i), 'w')\n",
    "        for edge in edges_20:\n",
    "            file.write('{} {}\\n'.format(edge[0], edge[1]))\n",
    "        file.close()\n",
    "        \n",
    "        file = open('../Edges/edges_80_{}_{}.txt'.format(ego_node, i), 'w')\n",
    "        for edge in edges_80:\n",
    "            file.write('{} {}\\n'.format(edge[0], edge[1]))\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('../Adjacency_Lists/')\n",
    "except:\n",
    "    pass\n",
    "for ego_node in ego_nodes:\n",
    "    for i in range(5):\n",
    "        file = open('../Edges/edges_80_{}_{}.txt'.format(ego_node, i), 'r')\n",
    "        adjacency_list = {}\n",
    "        for line in file:\n",
    "            if len(line) == 0:\n",
    "                continue\n",
    "            line = line.split()\n",
    "            node1, node2 = int(line[0]), int(line[1])\n",
    "            if node1 not in adjacency_list.keys():\n",
    "                adjacency_list[node1] = set()\n",
    "            if node2 not in adjacency_list.keys():\n",
    "                adjacency_list[node2] = set()\n",
    "            adjacency_list[node1].add(node2)\n",
    "            adjacency_list[node2].add(node1)\n",
    "        file.close()\n",
    "        keys = list(adjacency_list.keys())\n",
    "        keys.sort()\n",
    "\n",
    "        file = open('../Adjacency_Lists/adjacency_list_{}_{}.txt'.format(ego_node, i), 'w')\n",
    "        for key in keys:\n",
    "            file.write('{}'.format(key))\n",
    "            for node in adjacency_list[key]:\n",
    "                file.write(' {}'.format(node))\n",
    "            file.write('\\n')\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {}\n",
    "gender_featnum = []\n",
    "for ego_node in ego_nodes:\n",
    "    featnames = open(dataset_directory + str(ego_node) + '.featnames')\n",
    "    features_node = []\n",
    "    for line in featnames:\n",
    "        features_node.append(int(line.split(';')[-1].split()[-1]))\n",
    "        if line.split(';')[0].split()[1] == 'gender':\n",
    "            if int(line.split(';')[-1].split()[-1]) not in gender_featnum:\n",
    "                gender_featnum.append(int(line.split(';')[-1].split()[-1]))\n",
    "    features[ego_node] = features_node\n",
    "    featnames.close()\n",
    "gender_featnum.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_1 = {}\n",
    "gender_2 = {}\n",
    "for ego_node in ego_nodes:\n",
    "    egofeat = open(dataset_directory + str(ego_node) + '.egofeat')\n",
    "    feat = open(dataset_directory + str(ego_node) + '.feat')\n",
    "    index_gender_1 = features[ego_node].index(gender_featnum[0])\n",
    "    index_gender_2 = features[ego_node].index(gender_featnum[1])\n",
    "    for line in egofeat:\n",
    "        if int(line.split()[index_gender_1]) == 1:\n",
    "            gender_1[ego_node] = 1\n",
    "        else:\n",
    "            gender_1[ego_node] = 0\n",
    "        if int(line.split()[index_gender_2]) == 1:\n",
    "            gender_2[ego_node] = 1\n",
    "        else:\n",
    "            gender_2[ego_node] = 0\n",
    "    for line in feat:\n",
    "        if int(line.split()[index_gender_1 + 1]) == 1:\n",
    "            gender_1[int(line.split()[0])] = 1\n",
    "        else:\n",
    "            gender_1[int(line.split()[0])] = 0\n",
    "        if int(line.split()[index_gender_2 + 1]) == 1:\n",
    "            gender_2[int(line.split()[0])] = 1\n",
    "        else:\n",
    "            gender_2[int(line.split()[0])] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('../Gender_Adjacency_Lists/')\n",
    "except:\n",
    "    pass\n",
    "for ego_node in ego_nodes:\n",
    "    for i in range(5):\n",
    "        gender_wise_adjacency_list = {}\n",
    "        file = open('../Adjacency_Lists/adjacency_list_{}_{}.txt'.format(ego_node, i), 'r')\n",
    "        for line in file:\n",
    "            if len(line) == 0:\n",
    "                continue\n",
    "            line = line.split()\n",
    "            gender_wise_adjacency_list[int(line[0])] = []\n",
    "            gender_1_list = [int(n) for n in line[1:] if gender_1[int(n)] == 1]\n",
    "            gender_2_list = [int(n) for n in line[1:] if gender_2[int(n)] == 1]\n",
    "            gender_3_list = [int(n) for n in line[1:] if (gender_1[int(n)] == 0 and gender_2[int(n)] == 0)]\n",
    "            gender_wise_adjacency_list[int(line[0])].append(gender_1_list)\n",
    "            gender_wise_adjacency_list[int(line[0])].append(gender_2_list)\n",
    "            gender_wise_adjacency_list[int(line[0])].append(gender_3_list)\n",
    "        file.close()\n",
    "        keys = list(gender_wise_adjacency_list.keys())\n",
    "        keys.sort()\n",
    "        file = open('../Gender_Adjacency_Lists/gender_wise_adjacency_list_{}_{}.txt'.format(ego_node, i), 'w')\n",
    "        for key in keys:\n",
    "            file.write('{}\\n'.format(key))\n",
    "            for elements in gender_wise_adjacency_list[key]:\n",
    "                line = ''\n",
    "                for element in elements:\n",
    "                    line = line + str(element) + ' '\n",
    "                file.write(line.strip() + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('../Fairwalks/')\n",
    "except:\n",
    "    pass\n",
    "num_walks = 20\n",
    "walk_len = 80\n",
    "gender_choices = [0, 1, 2]\n",
    "gender_choices_not_0 = [1, 2]\n",
    "gender_choices_not_1 = [0, 2]\n",
    "gender_choices_not_2 = [0, 1]\n",
    "\n",
    "for ego_node in ego_nodes:\n",
    "    for i in range(5):\n",
    "        file = open('../Gender_Adjacency_Lists/gender_wise_adjacency_list_{}_{}.txt'.format(ego_node, i), 'r')\n",
    "        gender_wise_adjacency_list = {}\n",
    "        lines = file.readlines()\n",
    "        j = 0\n",
    "        while j < len(lines) and len(lines[j].strip()) != 0:\n",
    "            node = int(lines[j].strip())\n",
    "            gender_wise_adjacency_list[node] = []\n",
    "            for k in range(3):\n",
    "                j += 1\n",
    "                gender_wise_adjacency_list[node].append([int(n) for n in lines[j].strip().split()])\n",
    "            j += 1\n",
    "        nodes = [int(n.strip()) for n in lines[::4]]\n",
    "        file.close()\n",
    "        file = open('../Fairwalks/fairwalks_{}_{}.txt'.format(ego_node, i), 'w')\n",
    "        for walk in range(num_walks):\n",
    "            for node in nodes:\n",
    "                prev_node = -1\n",
    "                trace = []\n",
    "                current_node = node\n",
    "                for covered_len in range(walk_len):\n",
    "                    trace.append(current_node)\n",
    "                    if len(gender_wise_adjacency_list[current_node][0]) == 0 and len(gender_wise_adjacency_list[current_node][1]) == 0:\n",
    "                        gender_choice = 2\n",
    "                    elif len(gender_wise_adjacency_list[current_node][0]) == 0 and len(gender_wise_adjacency_list[current_node][2]) == 0:\n",
    "                        gender_choice = 1\n",
    "                    elif len(gender_wise_adjacency_list[current_node][1]) == 0 and len(gender_wise_adjacency_list[current_node][2]) == 0:\n",
    "                        gender_choice = 0\n",
    "                    elif len(gender_wise_adjacency_list[current_node][2]) == 0:\n",
    "                        gender_choice = random.choice(gender_choices_not_2)\n",
    "                    elif len(gender_wise_adjacency_list[current_node][1]) == 0:\n",
    "                        gender_choice = random.choice(gender_choices_not_1)\n",
    "                    elif len(gender_wise_adjacency_list[current_node][0]) == 0:\n",
    "                        gender_choice = random.choice(gender_choices_not_0)\n",
    "                    else:\n",
    "                        gender_choice = random.choice(gender_choices)\n",
    "                    next_node = random.choice(gender_wise_adjacency_list[current_node][gender_choice])\n",
    "                    prev_node = current_node\n",
    "                    current_node = next_node\n",
    "                line = ''\n",
    "                for step in trace:\n",
    "                    line = line + str(step) + ' '\n",
    "                file.write(line.strip() + '\\n')\n",
    "                line = ''\n",
    "                for step in trace[::-1]:\n",
    "                    line = line + str(step) + ' '\n",
    "                file.write(line.strip() + '\\n')\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('../Embeddings')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "for ego_node in ego_nodes:\n",
    "    for i in range(5):\n",
    "        file = open('../Fairwalks/fairwalks_{}_{}.txt'.format(ego_node, i), 'r')\n",
    "        walks = []\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            if len(line) == 0:\n",
    "                continue\n",
    "            walk = [element for element in line.strip().split()]\n",
    "            walks.append(walk)\n",
    "        model = Word2Vec(walks, size = 128, window = 10, min_count = 10, sg = 1, workers = mp.cpu_count())\n",
    "        model.wv.save_word2vec_format('../Embeddings/embeddings_{}_{}.emb'.format(ego_node, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ego_node in ego_nodes:\n",
    "    file = open('../Embeddings/' + str(ego_node) + '.emb')\n",
    "    lines = file.readlines()\n",
    "    num_nodes, ndims = int(lines[0].strip().split()[0]),int(lines[0].strip().split()[1])\n",
    "\n",
    "    embeddings = {}\n",
    "    for line in lines[1:]:\n",
    "        line = line.strip()\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        line = line.split()\n",
    "        node = int(line[0])\n",
    "        embeddings[node] = np.asarray([float(element) for element in line[1:]], dtype = np.float32)\n",
    "\n",
    "    nodes = list(embeddings.keys())\n",
    "    nodes.sort()\n",
    "\n",
    "    hadamard_vectors = {}\n",
    "    for i in range(len(nodes)):\n",
    "        node1 = nodes[i]\n",
    "        for node2 in nodes[i + 1:]:\n",
    "            hadamard_vectors[(node1, node2)] = np.multiply(embeddings[node1], embeddings[node2])\n",
    "        print(node1)\n",
    "\n",
    "    file2 = open('../Embeddings/hadamard_' + str(ego_node) + '.txt', 'w')\n",
    "    for i in range(len(nodes)):\n",
    "        node1 = nodes[i]\n",
    "        for node2 in nodes[i + 1:]:\n",
    "            file2.write(str(node1) + ' ' + str(node2) + ' ')\n",
    "            string = ''\n",
    "            for element in hadamard_vectors[(node1, node2)]:\n",
    "                string = string + str(element) + ' '\n",
    "            file2.write(string)\n",
    "            file2.write('\\n')\n",
    "    file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hadamard_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_lists[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../Embeddings/'\n",
    "ego_node = ego_nodes[0]\n",
    "X_nodes = []\n",
    "X = []\n",
    "y = []\n",
    "file = open(directory + 'hadamard_' + str(ego_node) + '.txt', 'r')\n",
    "adjacency_list = adjacency_lists[ego_node]\n",
    "lines = file.readlines()\n",
    "for line in lines:\n",
    "    if len(line) == 0:\n",
    "        continue\n",
    "    line = line.split()\n",
    "    node1, node2 = int(line[0]), int(line[1])\n",
    "    X_nodes.append([node1, node2])\n",
    "    if node2 in adjacency_list[node1]:\n",
    "        y.append(1)\n",
    "    else:\n",
    "        y.append(0)\n",
    "    vectors = [float(element) for element in line[2:]]\n",
    "    X.append(vectors)\n",
    "\n",
    "X_nodes = np.array(X_nodes)\n",
    "X = np.array(X, dtype = np.float32)\n",
    "y = np.array(y, dtype = np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_labels = model.predict(X_test)\n",
    "rf_probs = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Calculate roc auc\n",
    "roc_value = roc_auc_score(y_test, rf_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = len(rf_labels[rf_labels == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false = len(rf_labels[rf_labels == False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "11546 / (11546 + 185)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
